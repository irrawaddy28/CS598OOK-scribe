\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\@writefile{toc}{\contentsline {section}{\numberline {1}Mixture Models}{1}{section.0.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Representation}{1}{subsection.0.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Directed Graphical Model representing a Mixture Model}}{1}{figure.0.1}}
\newlabel{fig:DAG-MM}{{1}{1}{Directed Graphical Model representing a Mixture Model}{figure.0.1}{}}
\newlabel{eq:MixModel}{{1}{1}{Representation}{equation.0.1.1}{}}
\newlabel{eq:Zsumto1}{{2}{2}{Representation}{equation.0.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Inference and Learning}{2}{subsection.0.1.2}}
\newlabel{eq:ZgivenX}{{3}{2}{Inference and Learning}{equation.0.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Learning Mixture Models Using Parametric Distributions}{2}{subsection.0.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Directed Graphical Model representing a Mixture Model for $N$ i.i.d. data points $\mathbf  {X}_{i}$, where $i = 1, \cdots  , N$. The corresponding hidden variables are given by $Z_{i}$. The independence of $N$ observations is indicated by the plate.}}{3}{figure.0.2}}
\newlabel{fig:DAG-MM-IID}{{2}{3}{Directed Graphical Model representing a Mixture Model for $N$ i.i.d. data points $\data {X}_{i}$, where $i = 1, \cdots , N$. The corresponding hidden variables are given by $Z_{i}$. The independence of $N$ observations is indicated by the plate}{figure.0.2}{}}
\newlabel{eq:jointdensityiid}{{4}{3}{Learning Mixture Models Using Parametric Distributions}{equation.0.1.4}{}}
\newlabel{eq:MixModeliid0}{{5}{3}{Learning Mixture Models Using Parametric Distributions}{equation.0.1.5}{}}
\newlabel{eq:MixModeliid}{{6}{4}{Learning Mixture Models Using Parametric Distributions}{equation.0.1.6}{}}
\newlabel{eq:MixModelLearningProblem}{{7}{4}{Learning Mixture Models Using Parametric Distributions}{equation.0.1.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Gaussian Mixture Model}{4}{subsection.0.1.4}}
\newlabel{eq:GaussianComponent}{{8}{4}{Gaussian Mixture Model}{equation.0.1.8}{}}
\newlabel{eq:GMM1}{{9}{4}{Gaussian Mixture Model}{equation.0.1.9}{}}
\citation{Dempster-EM}
\newlabel{eq:GMMLearningProblem}{{11}{5}{Gaussian Mixture Model}{equation.0.1.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Determining the number of components ($K$) in a Mixture Model}{5}{subsection.0.1.5}}
\bibstyle{ims}
\bibdata{scribe}
\bibcite{Dempster-EM}{{1}{1977}{{Dempster et~al.}}{{Dempster, Laird and Rubin}}}
